{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85637e40",
   "metadata": {},
   "source": [
    "# Project_4: Diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "df0d3c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import sklearn as skl\n",
    "import keras_tuner as kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a24fe6c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>smoking_history</th>\n",
       "      <th>bmi</th>\n",
       "      <th>HbA1c_level</th>\n",
       "      <th>blood_glucose_level</th>\n",
       "      <th>diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Female</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>never</td>\n",
       "      <td>25.19</td>\n",
       "      <td>6.6</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Female</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No Info</td>\n",
       "      <td>27.32</td>\n",
       "      <td>6.6</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Male</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>never</td>\n",
       "      <td>27.32</td>\n",
       "      <td>5.7</td>\n",
       "      <td>158</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Female</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>current</td>\n",
       "      <td>23.45</td>\n",
       "      <td>5.0</td>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Male</td>\n",
       "      <td>76.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>current</td>\n",
       "      <td>20.14</td>\n",
       "      <td>4.8</td>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender   age  hypertension  heart_disease smoking_history    bmi  \\\n",
       "0  Female  80.0             0              1           never  25.19   \n",
       "1  Female  54.0             0              0         No Info  27.32   \n",
       "2    Male  28.0             0              0           never  27.32   \n",
       "3  Female  36.0             0              0         current  23.45   \n",
       "4    Male  76.0             1              1         current  20.14   \n",
       "\n",
       "   HbA1c_level  blood_glucose_level  diabetes  \n",
       "0          6.6                  140         0  \n",
       "1          6.6                   80         0  \n",
       "2          5.7                  158         0  \n",
       "3          5.0                  155         0  \n",
       "4          4.8                  155         0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(Path(\"../Resources/diabetes_prediction_dataset.csv\"))\n",
    "\n",
    "\n",
    "\n",
    "df.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2fa3e272",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gender                  object\n",
       "age                    float64\n",
       "hypertension             int64\n",
       "heart_disease            int64\n",
       "smoking_history         object\n",
       "bmi                    float64\n",
       "HbA1c_level            float64\n",
       "blood_glucose_level      int64\n",
       "diabetes                 int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9573612",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "175842bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>96146.0</td>\n",
       "      <td>41.794326</td>\n",
       "      <td>22.462948</td>\n",
       "      <td>0.08</td>\n",
       "      <td>24.0</td>\n",
       "      <td>43.00</td>\n",
       "      <td>59.00</td>\n",
       "      <td>80.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hypertension</th>\n",
       "      <td>96146.0</td>\n",
       "      <td>0.077601</td>\n",
       "      <td>0.267544</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>heart_disease</th>\n",
       "      <td>96146.0</td>\n",
       "      <td>0.040803</td>\n",
       "      <td>0.197833</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bmi</th>\n",
       "      <td>96146.0</td>\n",
       "      <td>27.321461</td>\n",
       "      <td>6.767716</td>\n",
       "      <td>10.01</td>\n",
       "      <td>23.4</td>\n",
       "      <td>27.32</td>\n",
       "      <td>29.86</td>\n",
       "      <td>95.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HbA1c_level</th>\n",
       "      <td>96146.0</td>\n",
       "      <td>5.532609</td>\n",
       "      <td>1.073232</td>\n",
       "      <td>3.50</td>\n",
       "      <td>4.8</td>\n",
       "      <td>5.80</td>\n",
       "      <td>6.20</td>\n",
       "      <td>9.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blood_glucose_level</th>\n",
       "      <td>96146.0</td>\n",
       "      <td>138.218231</td>\n",
       "      <td>40.909771</td>\n",
       "      <td>80.00</td>\n",
       "      <td>100.0</td>\n",
       "      <td>140.00</td>\n",
       "      <td>159.00</td>\n",
       "      <td>300.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diabetes</th>\n",
       "      <td>96146.0</td>\n",
       "      <td>0.088220</td>\n",
       "      <td>0.283616</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       count        mean        std    min    25%     50%  \\\n",
       "age                  96146.0   41.794326  22.462948   0.08   24.0   43.00   \n",
       "hypertension         96146.0    0.077601   0.267544   0.00    0.0    0.00   \n",
       "heart_disease        96146.0    0.040803   0.197833   0.00    0.0    0.00   \n",
       "bmi                  96146.0   27.321461   6.767716  10.01   23.4   27.32   \n",
       "HbA1c_level          96146.0    5.532609   1.073232   3.50    4.8    5.80   \n",
       "blood_glucose_level  96146.0  138.218231  40.909771  80.00  100.0  140.00   \n",
       "diabetes             96146.0    0.088220   0.283616   0.00    0.0    0.00   \n",
       "\n",
       "                        75%     max  \n",
       "age                   59.00   80.00  \n",
       "hypertension           0.00    1.00  \n",
       "heart_disease          0.00    1.00  \n",
       "bmi                   29.86   95.69  \n",
       "HbA1c_level            6.20    9.00  \n",
       "blood_glucose_level  159.00  300.00  \n",
       "diabetes               0.00    1.00  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57e82464",
   "metadata": {},
   "outputs": [],
   "source": [
    "# repalce na gender\n",
    "\n",
    "df['gender'].fillna(df['gender'].mode()[0], inplace=True)\n",
    "\n",
    "# map out gender into a binary form\n",
    "binary_mapping = {'Female':1,'Male':0,'Other':3}\n",
    "df['gender'] = df['gender'].map(binary_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0c5cf7a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>bmi</th>\n",
       "      <th>HbA1c_level</th>\n",
       "      <th>blood_glucose_level</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>No Info</th>\n",
       "      <th>current</th>\n",
       "      <th>ever</th>\n",
       "      <th>former</th>\n",
       "      <th>never</th>\n",
       "      <th>not current</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>25.19</td>\n",
       "      <td>6.6</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27.32</td>\n",
       "      <td>6.6</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27.32</td>\n",
       "      <td>5.7</td>\n",
       "      <td>158</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.45</td>\n",
       "      <td>5.0</td>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20.14</td>\n",
       "      <td>4.8</td>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender   age  hypertension  heart_disease    bmi  HbA1c_level  \\\n",
       "0       1  80.0             0              1  25.19          6.6   \n",
       "1       1  54.0             0              0  27.32          6.6   \n",
       "2       0  28.0             0              0  27.32          5.7   \n",
       "3       1  36.0             0              0  23.45          5.0   \n",
       "4       0  76.0             1              1  20.14          4.8   \n",
       "\n",
       "   blood_glucose_level  diabetes  No Info  current  ever  former  never  \\\n",
       "0                  140         0      0.0      0.0   0.0     0.0    1.0   \n",
       "1                   80         0      1.0      0.0   0.0     0.0    0.0   \n",
       "2                  158         0      0.0      0.0   0.0     0.0    1.0   \n",
       "3                  155         0      0.0      1.0   0.0     0.0    0.0   \n",
       "4                  155         0      0.0      1.0   0.0     0.0    0.0   \n",
       "\n",
       "   not current  \n",
       "0          0.0  \n",
       "1          0.0  \n",
       "2          0.0  \n",
       "3          0.0  \n",
       "4          0.0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "sh_dummies = pd.get_dummies(df['smoking_history'], dtype = float)\n",
    "df = pd.concat([df, sh_dummies], axis = 1)\n",
    "df = df.drop([\"smoking_history\"], axis = 1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "56f945fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gender</th>\n",
       "      <td>96146.0</td>\n",
       "      <td>0.584684</td>\n",
       "      <td>0.493918</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>96146.0</td>\n",
       "      <td>41.794326</td>\n",
       "      <td>22.462948</td>\n",
       "      <td>0.08</td>\n",
       "      <td>24.0</td>\n",
       "      <td>43.00</td>\n",
       "      <td>59.00</td>\n",
       "      <td>80.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hypertension</th>\n",
       "      <td>96146.0</td>\n",
       "      <td>0.077601</td>\n",
       "      <td>0.267544</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>heart_disease</th>\n",
       "      <td>96146.0</td>\n",
       "      <td>0.040803</td>\n",
       "      <td>0.197833</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bmi</th>\n",
       "      <td>96146.0</td>\n",
       "      <td>27.321461</td>\n",
       "      <td>6.767716</td>\n",
       "      <td>10.01</td>\n",
       "      <td>23.4</td>\n",
       "      <td>27.32</td>\n",
       "      <td>29.86</td>\n",
       "      <td>95.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HbA1c_level</th>\n",
       "      <td>96146.0</td>\n",
       "      <td>5.532609</td>\n",
       "      <td>1.073232</td>\n",
       "      <td>3.50</td>\n",
       "      <td>4.8</td>\n",
       "      <td>5.80</td>\n",
       "      <td>6.20</td>\n",
       "      <td>9.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blood_glucose_level</th>\n",
       "      <td>96146.0</td>\n",
       "      <td>138.218231</td>\n",
       "      <td>40.909771</td>\n",
       "      <td>80.00</td>\n",
       "      <td>100.0</td>\n",
       "      <td>140.00</td>\n",
       "      <td>159.00</td>\n",
       "      <td>300.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diabetes</th>\n",
       "      <td>96146.0</td>\n",
       "      <td>0.088220</td>\n",
       "      <td>0.283616</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>No Info</th>\n",
       "      <td>96146.0</td>\n",
       "      <td>0.342053</td>\n",
       "      <td>0.474400</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>current</th>\n",
       "      <td>96146.0</td>\n",
       "      <td>0.095657</td>\n",
       "      <td>0.294121</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ever</th>\n",
       "      <td>96146.0</td>\n",
       "      <td>0.041583</td>\n",
       "      <td>0.199634</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>former</th>\n",
       "      <td>96146.0</td>\n",
       "      <td>0.096717</td>\n",
       "      <td>0.295574</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>never</th>\n",
       "      <td>96146.0</td>\n",
       "      <td>0.357768</td>\n",
       "      <td>0.479346</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>not current</th>\n",
       "      <td>96146.0</td>\n",
       "      <td>0.066222</td>\n",
       "      <td>0.248671</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       count        mean        std    min    25%     50%  \\\n",
       "gender               96146.0    0.584684   0.493918   0.00    0.0    1.00   \n",
       "age                  96146.0   41.794326  22.462948   0.08   24.0   43.00   \n",
       "hypertension         96146.0    0.077601   0.267544   0.00    0.0    0.00   \n",
       "heart_disease        96146.0    0.040803   0.197833   0.00    0.0    0.00   \n",
       "bmi                  96146.0   27.321461   6.767716  10.01   23.4   27.32   \n",
       "HbA1c_level          96146.0    5.532609   1.073232   3.50    4.8    5.80   \n",
       "blood_glucose_level  96146.0  138.218231  40.909771  80.00  100.0  140.00   \n",
       "diabetes             96146.0    0.088220   0.283616   0.00    0.0    0.00   \n",
       "No Info              96146.0    0.342053   0.474400   0.00    0.0    0.00   \n",
       "current              96146.0    0.095657   0.294121   0.00    0.0    0.00   \n",
       "ever                 96146.0    0.041583   0.199634   0.00    0.0    0.00   \n",
       "former               96146.0    0.096717   0.295574   0.00    0.0    0.00   \n",
       "never                96146.0    0.357768   0.479346   0.00    0.0    0.00   \n",
       "not current          96146.0    0.066222   0.248671   0.00    0.0    0.00   \n",
       "\n",
       "                        75%     max  \n",
       "gender                 1.00    3.00  \n",
       "age                   59.00   80.00  \n",
       "hypertension           0.00    1.00  \n",
       "heart_disease          0.00    1.00  \n",
       "bmi                   29.86   95.69  \n",
       "HbA1c_level            6.20    9.00  \n",
       "blood_glucose_level  159.00  300.00  \n",
       "diabetes               0.00    1.00  \n",
       "No Info                1.00    1.00  \n",
       "current                0.00    1.00  \n",
       "ever                   0.00    1.00  \n",
       "former                 0.00    1.00  \n",
       "never                  1.00    1.00  \n",
       "not current            0.00    1.00  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7fe92fd",
   "metadata": {},
   "source": [
    "# General graphing and analyzing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fb7061",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AVG A1c diabetes vs not diabetes\n",
    "\n",
    "# AVG blood glucose level diabets not diabetes\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5beaf350",
   "metadata": {},
   "source": [
    "# Predict Daibetes Risk based off the factors given using a linear regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc0fc7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['diabetes']\n",
    "columns_to_exclude = ['diabetes']\n",
    "X = df.drop(columns= columns_to_exclude)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "136c2242",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(72109, 13)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    random_state=1, \n",
    "                                                    stratify=y)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9359d3cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=200, random_state=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=200, random_state=1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=200, random_state=1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression(solver='lbfgs',\n",
    "                                max_iter=200,\n",
    "                                random_state=1)\n",
    "classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fd250354",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mille\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=200, random_state=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=200, random_state=1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=200, random_state=1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b801d5c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.9590065040424912\n",
      "Testing Data Score: 0.9599783666846944\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training Data Score: {classifier.score(X_train, y_train)}\")\n",
    "print(f\"Testing Data Score: {classifier.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "410a6e2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Prediction  Actual\n",
       "0           0       0\n",
       "1           0       0\n",
       "2           0       0\n",
       "3           0       0\n",
       "4           0       0\n",
       "5           0       0\n",
       "6           0       0\n",
       "7           0       0\n",
       "8           0       0\n",
       "9           0       0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prediction\n",
    "\n",
    "predictions = classifier.predict(X_test)\n",
    "results = pd.DataFrame({\"Prediction\": predictions, \"Actual\": y_test}).reset_index(drop=True)\n",
    "results.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "85bbccf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9599783666846944"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "# Display the accuracy score for the test dataset.\n",
    "accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "12f79d31",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix = confusion_matrix(y_test,predictions)\n",
    "\n",
    "\n",
    "label_names = ['No Diabetes','Diabetes']\n",
    "confusion_matrix_df = pd.DataFrame(confusion_matrix,index=label_names,columns = label_names)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(confusion_matrix_df, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bb324893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "No Diabetes        0.96      0.99      0.98     21916\n",
      "    Diabetes       0.89      0.63      0.73      2121\n",
      "\n",
      "    accuracy                           0.96     24037\n",
      "   macro avg       0.93      0.81      0.86     24037\n",
      "weighted avg       0.96      0.96      0.96     24037\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "target_names = [\"No Diabetes \", \"Diabetes\"]\n",
    "print(classification_report(y_test, predictions, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07001734",
   "metadata": {},
   "source": [
    "# Optimization by scaling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "41cfba73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale the data\n",
    "X_scaler = skl.preprocessing.StandardScaler()\n",
    "\n",
    "# Fit the scaler\n",
    "X_scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bef259fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=200, random_state=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=200, random_state=1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=200, random_state=1)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "classifier = LogisticRegression(solver='lbfgs',\n",
    "                                max_iter=200,\n",
    "                                random_state=1)\n",
    "classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "35033420",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=200, random_state=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=200, random_state=1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=200, random_state=1)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train_scaled,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f6a524da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.9586736745759892\n",
      "Testing Data Score: 0.9597287515080917\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training Data Score: {classifier.score(X_train_scaled, y_train)}\")\n",
    "print(f\"Testing Data Score: {classifier.score(X_test_scaled, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c0d14c05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Prediction  Actual\n",
       "0           0       0\n",
       "1           0       0\n",
       "2           0       0\n",
       "3           0       0\n",
       "4           0       0\n",
       "5           0       0\n",
       "6           0       0\n",
       "7           0       0\n",
       "8           0       0\n",
       "9           0       0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_predictions =classifier.predict(X_test_scaled)\n",
    "\n",
    "\n",
    "scaled_results = pd.DataFrame({\"Prediction\": scaled_predictions, \"Actual\": y_test}).reset_index(drop=True)\n",
    "results.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "76b3c565",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9597287515080917"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, scaled_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b24b691",
   "metadata": {},
   "source": [
    "sacling the data didnt improve the accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e764d8e",
   "metadata": {},
   "source": [
    "# Using a nueral network model on the data to see if we can imrpove the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b38265b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mille\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_6\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_6\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">84</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">42</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │               <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_19 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)                   │              \u001b[38;5;34m84\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_20 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)                   │              \u001b[38;5;34m42\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_21 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │               \u001b[38;5;34m7\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">133</span> (532.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m133\u001b[0m (532.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">133</span> (532.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m133\u001b[0m (532.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#  create the karas sequential model\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# add hidden layer\n",
    "input_features= len(X_train.columns)\n",
    "\n",
    "nn.add(tf.keras.layers.Dense(units=6,input_dim = input_features, activation = \"relu\" ))\n",
    "\n",
    "nn.add(tf.keras.layers.Dense(units=6,activation = \"relu\" ))\n",
    "\n",
    "nn.add(tf.keras.layers.Dense(units = 1,activation =\"sigmoid\"))\n",
    "\n",
    "\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "756ec447",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0678e8b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 578us/step - accuracy: 0.7942 - loss: 1.6002\n",
      "Epoch 2/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 578us/step - accuracy: 0.9170 - loss: 0.2631\n",
      "Epoch 3/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 572us/step - accuracy: 0.9248 - loss: 0.2259\n",
      "Epoch 4/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 557us/step - accuracy: 0.9356 - loss: 0.1891\n",
      "Epoch 5/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 550us/step - accuracy: 0.9422 - loss: 0.1656\n",
      "Epoch 6/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 544us/step - accuracy: 0.9483 - loss: 0.1488\n",
      "Epoch 7/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 551us/step - accuracy: 0.9507 - loss: 0.1405\n",
      "Epoch 8/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 544us/step - accuracy: 0.9533 - loss: 0.1332\n",
      "Epoch 9/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 541us/step - accuracy: 0.9533 - loss: 0.1313\n",
      "Epoch 10/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 541us/step - accuracy: 0.9526 - loss: 0.1307\n",
      "Epoch 11/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 544us/step - accuracy: 0.9544 - loss: 0.1271\n",
      "Epoch 12/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 541us/step - accuracy: 0.9537 - loss: 0.1256\n",
      "Epoch 13/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 533us/step - accuracy: 0.9553 - loss: 0.1228\n",
      "Epoch 14/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 535us/step - accuracy: 0.9560 - loss: 0.1222\n",
      "Epoch 15/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 534us/step - accuracy: 0.9550 - loss: 0.1213\n",
      "Epoch 16/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 533us/step - accuracy: 0.9556 - loss: 0.1212\n",
      "Epoch 17/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 533us/step - accuracy: 0.9560 - loss: 0.1206\n",
      "Epoch 18/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 536us/step - accuracy: 0.9542 - loss: 0.1228\n",
      "Epoch 19/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 541us/step - accuracy: 0.9544 - loss: 0.1232\n",
      "Epoch 20/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 543us/step - accuracy: 0.9548 - loss: 0.1216\n",
      "Epoch 21/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 537us/step - accuracy: 0.9536 - loss: 0.1238\n",
      "Epoch 22/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 549us/step - accuracy: 0.9551 - loss: 0.1218\n",
      "Epoch 23/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 536us/step - accuracy: 0.9547 - loss: 0.1247\n",
      "Epoch 24/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 533us/step - accuracy: 0.9555 - loss: 0.1211\n",
      "Epoch 25/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 525us/step - accuracy: 0.9540 - loss: 0.1238\n",
      "Epoch 26/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 530us/step - accuracy: 0.9551 - loss: 0.1195\n",
      "Epoch 27/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 538us/step - accuracy: 0.9558 - loss: 0.1215\n",
      "Epoch 28/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 540us/step - accuracy: 0.9564 - loss: 0.1203\n",
      "Epoch 29/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 537us/step - accuracy: 0.9572 - loss: 0.1185\n",
      "Epoch 30/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 542us/step - accuracy: 0.9541 - loss: 0.1241\n",
      "Epoch 31/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 544us/step - accuracy: 0.9554 - loss: 0.1201\n",
      "Epoch 32/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 551us/step - accuracy: 0.9564 - loss: 0.1187\n",
      "Epoch 33/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 539us/step - accuracy: 0.9544 - loss: 0.1222\n",
      "Epoch 34/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 542us/step - accuracy: 0.9545 - loss: 0.1231\n",
      "Epoch 35/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 556us/step - accuracy: 0.9548 - loss: 0.1204\n",
      "Epoch 36/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 548us/step - accuracy: 0.9558 - loss: 0.1206\n",
      "Epoch 37/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 545us/step - accuracy: 0.9549 - loss: 0.1233\n",
      "Epoch 38/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 548us/step - accuracy: 0.9551 - loss: 0.1204\n",
      "Epoch 39/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 565us/step - accuracy: 0.9549 - loss: 0.1228\n",
      "Epoch 40/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 560us/step - accuracy: 0.9560 - loss: 0.1207\n",
      "Epoch 41/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 553us/step - accuracy: 0.9551 - loss: 0.1216\n",
      "Epoch 42/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 569us/step - accuracy: 0.9551 - loss: 0.1211\n",
      "Epoch 43/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 545us/step - accuracy: 0.9555 - loss: 0.1209\n",
      "Epoch 44/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 552us/step - accuracy: 0.9548 - loss: 0.1213\n",
      "Epoch 45/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 538us/step - accuracy: 0.9555 - loss: 0.1202\n",
      "Epoch 46/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 551us/step - accuracy: 0.9560 - loss: 0.1221\n",
      "Epoch 47/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 549us/step - accuracy: 0.9556 - loss: 0.1201\n",
      "Epoch 48/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 536us/step - accuracy: 0.9540 - loss: 0.1224\n",
      "Epoch 49/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 544us/step - accuracy: 0.9542 - loss: 0.1233\n",
      "Epoch 50/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 550us/step - accuracy: 0.9556 - loss: 0.1213\n",
      "Epoch 51/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 559us/step - accuracy: 0.9546 - loss: 0.1226\n",
      "Epoch 52/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 555us/step - accuracy: 0.9550 - loss: 0.1222\n",
      "Epoch 53/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 557us/step - accuracy: 0.9540 - loss: 0.1218\n",
      "Epoch 54/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 557us/step - accuracy: 0.9565 - loss: 0.1184\n",
      "Epoch 55/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 549us/step - accuracy: 0.9560 - loss: 0.1188\n",
      "Epoch 56/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 542us/step - accuracy: 0.9551 - loss: 0.1213\n",
      "Epoch 57/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 552us/step - accuracy: 0.9562 - loss: 0.1186\n",
      "Epoch 58/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 550us/step - accuracy: 0.9573 - loss: 0.1174\n",
      "Epoch 59/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 542us/step - accuracy: 0.9563 - loss: 0.1190\n",
      "Epoch 60/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 540us/step - accuracy: 0.9542 - loss: 0.1217\n",
      "Epoch 61/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 533us/step - accuracy: 0.9560 - loss: 0.1193\n",
      "Epoch 62/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 541us/step - accuracy: 0.9569 - loss: 0.1170\n",
      "Epoch 63/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 546us/step - accuracy: 0.9563 - loss: 0.1193\n",
      "Epoch 64/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 542us/step - accuracy: 0.9545 - loss: 0.1202\n",
      "Epoch 65/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 532us/step - accuracy: 0.9555 - loss: 0.1203\n",
      "Epoch 66/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 528us/step - accuracy: 0.9565 - loss: 0.1195\n",
      "Epoch 67/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 527us/step - accuracy: 0.9557 - loss: 0.1190\n",
      "Epoch 68/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 534us/step - accuracy: 0.9545 - loss: 0.1234\n",
      "Epoch 69/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 535us/step - accuracy: 0.9558 - loss: 0.1194\n",
      "Epoch 70/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 542us/step - accuracy: 0.9567 - loss: 0.1178\n",
      "Epoch 71/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 540us/step - accuracy: 0.9554 - loss: 0.1191\n",
      "Epoch 72/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 539us/step - accuracy: 0.9558 - loss: 0.1193\n",
      "Epoch 73/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 531us/step - accuracy: 0.9554 - loss: 0.1196\n",
      "Epoch 74/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 529us/step - accuracy: 0.9568 - loss: 0.1198\n",
      "Epoch 75/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 528us/step - accuracy: 0.9554 - loss: 0.1200\n",
      "Epoch 76/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 530us/step - accuracy: 0.9562 - loss: 0.1183\n",
      "Epoch 77/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 534us/step - accuracy: 0.9576 - loss: 0.1154\n",
      "Epoch 78/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 535us/step - accuracy: 0.9557 - loss: 0.1220\n",
      "Epoch 79/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 569us/step - accuracy: 0.9551 - loss: 0.1198\n",
      "Epoch 80/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 578us/step - accuracy: 0.9556 - loss: 0.1198\n",
      "Epoch 81/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 563us/step - accuracy: 0.9561 - loss: 0.1193\n",
      "Epoch 82/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 549us/step - accuracy: 0.9558 - loss: 0.1216\n",
      "Epoch 83/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 565us/step - accuracy: 0.9560 - loss: 0.1205\n",
      "Epoch 84/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 570us/step - accuracy: 0.9539 - loss: 0.1227\n",
      "Epoch 85/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 560us/step - accuracy: 0.9563 - loss: 0.1205\n",
      "Epoch 86/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 558us/step - accuracy: 0.9573 - loss: 0.1172\n",
      "Epoch 87/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 558us/step - accuracy: 0.9566 - loss: 0.1187\n",
      "Epoch 88/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 549us/step - accuracy: 0.9580 - loss: 0.1147\n",
      "Epoch 89/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 558us/step - accuracy: 0.9556 - loss: 0.1210\n",
      "Epoch 90/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 560us/step - accuracy: 0.9570 - loss: 0.1157\n",
      "Epoch 91/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 555us/step - accuracy: 0.9570 - loss: 0.1174\n",
      "Epoch 92/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 559us/step - accuracy: 0.9553 - loss: 0.1194\n",
      "Epoch 93/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 545us/step - accuracy: 0.9559 - loss: 0.1189\n",
      "Epoch 94/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 559us/step - accuracy: 0.9564 - loss: 0.1179\n",
      "Epoch 95/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 553us/step - accuracy: 0.9562 - loss: 0.1177\n",
      "Epoch 96/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 554us/step - accuracy: 0.9562 - loss: 0.1196\n",
      "Epoch 97/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 546us/step - accuracy: 0.9570 - loss: 0.1190\n",
      "Epoch 98/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 536us/step - accuracy: 0.9565 - loss: 0.1186\n",
      "Epoch 99/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 531us/step - accuracy: 0.9563 - loss: 0.1187\n",
      "Epoch 100/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 527us/step - accuracy: 0.9574 - loss: 0.1156\n"
     ]
    }
   ],
   "source": [
    "fit_model = nn.fit(X_train, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a79afaa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "752/752 - 0s - 523us/step - accuracy: 0.9562 - loss: 0.1201\n",
      "Loss: 0.12011650949716568, Accuracy: 0.9561925530433655\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = nn.evaluate(X_test,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "315a74ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mille\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 567us/step - accuracy: 0.9172 - loss: 0.4768\n",
      "Epoch 2/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 552us/step - accuracy: 0.9274 - loss: 0.2243\n",
      "Epoch 3/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 544us/step - accuracy: 0.9345 - loss: 0.1874\n",
      "Epoch 4/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 542us/step - accuracy: 0.9391 - loss: 0.1657\n",
      "Epoch 5/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 539us/step - accuracy: 0.9461 - loss: 0.1505\n",
      "Epoch 6/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 540us/step - accuracy: 0.9509 - loss: 0.1364\n",
      "Epoch 7/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 535us/step - accuracy: 0.9535 - loss: 0.1296\n",
      "Epoch 8/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 533us/step - accuracy: 0.9553 - loss: 0.1273\n",
      "Epoch 9/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 515us/step - accuracy: 0.9559 - loss: 0.1237\n",
      "Epoch 10/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 525us/step - accuracy: 0.9560 - loss: 0.1209\n",
      "Epoch 11/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 525us/step - accuracy: 0.9575 - loss: 0.1198\n",
      "Epoch 12/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 523us/step - accuracy: 0.9592 - loss: 0.1150\n",
      "Epoch 13/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 520us/step - accuracy: 0.9598 - loss: 0.1141\n",
      "Epoch 14/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 523us/step - accuracy: 0.9588 - loss: 0.1160\n",
      "Epoch 15/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 516us/step - accuracy: 0.9591 - loss: 0.1136\n",
      "Epoch 16/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 541us/step - accuracy: 0.9591 - loss: 0.1144\n",
      "Epoch 17/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 541us/step - accuracy: 0.9604 - loss: 0.1122\n",
      "Epoch 18/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 544us/step - accuracy: 0.9598 - loss: 0.1134\n",
      "Epoch 19/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 548us/step - accuracy: 0.9593 - loss: 0.1142\n",
      "Epoch 20/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 541us/step - accuracy: 0.9596 - loss: 0.1128\n",
      "Epoch 21/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 540us/step - accuracy: 0.9601 - loss: 0.1133\n",
      "Epoch 22/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 540us/step - accuracy: 0.9597 - loss: 0.1127\n",
      "Epoch 23/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 537us/step - accuracy: 0.9589 - loss: 0.1138\n",
      "Epoch 24/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 538us/step - accuracy: 0.9614 - loss: 0.1095\n",
      "Epoch 25/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 570us/step - accuracy: 0.9601 - loss: 0.1112\n",
      "Epoch 26/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 554us/step - accuracy: 0.9609 - loss: 0.1096\n",
      "Epoch 27/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 520us/step - accuracy: 0.9594 - loss: 0.1125\n",
      "Epoch 28/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 514us/step - accuracy: 0.9602 - loss: 0.1103\n",
      "Epoch 29/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 524us/step - accuracy: 0.9620 - loss: 0.1069\n",
      "Epoch 30/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 525us/step - accuracy: 0.9602 - loss: 0.1110\n",
      "Epoch 31/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 521us/step - accuracy: 0.9617 - loss: 0.1084\n",
      "Epoch 32/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 529us/step - accuracy: 0.9622 - loss: 0.1082\n",
      "Epoch 33/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 523us/step - accuracy: 0.9617 - loss: 0.1080\n",
      "Epoch 34/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 521us/step - accuracy: 0.9612 - loss: 0.1081\n",
      "Epoch 35/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 523us/step - accuracy: 0.9614 - loss: 0.1078\n",
      "Epoch 36/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 516us/step - accuracy: 0.9610 - loss: 0.1085\n",
      "Epoch 37/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 506us/step - accuracy: 0.9617 - loss: 0.1072\n",
      "Epoch 38/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 513us/step - accuracy: 0.9618 - loss: 0.1080\n",
      "Epoch 39/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 545us/step - accuracy: 0.9615 - loss: 0.1097\n",
      "Epoch 40/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 550us/step - accuracy: 0.9596 - loss: 0.1103\n",
      "Epoch 41/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 541us/step - accuracy: 0.9620 - loss: 0.1079\n",
      "Epoch 42/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 538us/step - accuracy: 0.9631 - loss: 0.1072\n",
      "Epoch 43/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 531us/step - accuracy: 0.9622 - loss: 0.1079\n",
      "Epoch 44/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 548us/step - accuracy: 0.9619 - loss: 0.1072\n",
      "Epoch 45/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 527us/step - accuracy: 0.9622 - loss: 0.1062\n",
      "Epoch 46/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 532us/step - accuracy: 0.9620 - loss: 0.1071\n",
      "Epoch 47/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 528us/step - accuracy: 0.9627 - loss: 0.1086\n",
      "Epoch 48/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 526us/step - accuracy: 0.9600 - loss: 0.1102\n",
      "Epoch 49/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 525us/step - accuracy: 0.9620 - loss: 0.1065\n",
      "Epoch 50/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 516us/step - accuracy: 0.9618 - loss: 0.1078\n",
      "Epoch 51/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 559us/step - accuracy: 0.9619 - loss: 0.1080\n",
      "Epoch 52/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 568us/step - accuracy: 0.9620 - loss: 0.1077\n",
      "Epoch 53/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 561us/step - accuracy: 0.9614 - loss: 0.1080\n",
      "Epoch 54/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 539us/step - accuracy: 0.9621 - loss: 0.1068\n",
      "Epoch 55/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 541us/step - accuracy: 0.9607 - loss: 0.1075\n",
      "Epoch 56/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 540us/step - accuracy: 0.9616 - loss: 0.1077\n",
      "Epoch 57/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 548us/step - accuracy: 0.9625 - loss: 0.1057\n",
      "Epoch 58/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 526us/step - accuracy: 0.9621 - loss: 0.1064\n",
      "Epoch 59/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 525us/step - accuracy: 0.9628 - loss: 0.1050\n",
      "Epoch 60/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 540us/step - accuracy: 0.9620 - loss: 0.1067\n",
      "Epoch 61/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 544us/step - accuracy: 0.9630 - loss: 0.1051\n",
      "Epoch 62/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 534us/step - accuracy: 0.9624 - loss: 0.1053\n",
      "Epoch 63/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 556us/step - accuracy: 0.9616 - loss: 0.1077\n",
      "Epoch 64/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 534us/step - accuracy: 0.9621 - loss: 0.1068\n",
      "Epoch 65/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 541us/step - accuracy: 0.9631 - loss: 0.1043\n",
      "Epoch 66/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 554us/step - accuracy: 0.9624 - loss: 0.1075\n",
      "Epoch 67/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 533us/step - accuracy: 0.9633 - loss: 0.1034\n",
      "Epoch 68/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 532us/step - accuracy: 0.9621 - loss: 0.1071\n",
      "Epoch 69/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 533us/step - accuracy: 0.9632 - loss: 0.1042\n",
      "Epoch 70/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 525us/step - accuracy: 0.9632 - loss: 0.1048\n",
      "Epoch 71/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 526us/step - accuracy: 0.9637 - loss: 0.1034\n",
      "Epoch 72/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 525us/step - accuracy: 0.9624 - loss: 0.1065\n",
      "Epoch 73/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 518us/step - accuracy: 0.9618 - loss: 0.1080\n",
      "Epoch 74/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 519us/step - accuracy: 0.9625 - loss: 0.1049\n",
      "Epoch 75/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 530us/step - accuracy: 0.9628 - loss: 0.1037\n",
      "Epoch 76/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 539us/step - accuracy: 0.9636 - loss: 0.1030\n",
      "Epoch 77/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 535us/step - accuracy: 0.9627 - loss: 0.1063\n",
      "Epoch 78/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 539us/step - accuracy: 0.9627 - loss: 0.1050\n",
      "Epoch 79/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 557us/step - accuracy: 0.9641 - loss: 0.1050\n",
      "Epoch 80/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 536us/step - accuracy: 0.9629 - loss: 0.1066\n",
      "Epoch 81/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 532us/step - accuracy: 0.9620 - loss: 0.1072\n",
      "Epoch 82/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 535us/step - accuracy: 0.9629 - loss: 0.1078\n",
      "Epoch 83/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 534us/step - accuracy: 0.9629 - loss: 0.1057\n",
      "Epoch 84/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 553us/step - accuracy: 0.9624 - loss: 0.1053\n",
      "Epoch 85/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 533us/step - accuracy: 0.9640 - loss: 0.1033\n",
      "Epoch 86/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 537us/step - accuracy: 0.9644 - loss: 0.1017\n",
      "Epoch 87/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 534us/step - accuracy: 0.9638 - loss: 0.1030\n",
      "Epoch 88/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 528us/step - accuracy: 0.9630 - loss: 0.1041\n",
      "Epoch 89/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 531us/step - accuracy: 0.9651 - loss: 0.1018\n",
      "Epoch 90/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 547us/step - accuracy: 0.9628 - loss: 0.1046\n",
      "Epoch 91/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 548us/step - accuracy: 0.9626 - loss: 0.1059\n",
      "Epoch 92/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 553us/step - accuracy: 0.9640 - loss: 0.1035\n",
      "Epoch 93/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 542us/step - accuracy: 0.9638 - loss: 0.1031\n",
      "Epoch 94/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 536us/step - accuracy: 0.9611 - loss: 0.1071\n",
      "Epoch 95/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 561us/step - accuracy: 0.9631 - loss: 0.1056\n",
      "Epoch 96/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 553us/step - accuracy: 0.9638 - loss: 0.1038\n",
      "Epoch 97/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 551us/step - accuracy: 0.9640 - loss: 0.1015\n",
      "Epoch 98/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 543us/step - accuracy: 0.9643 - loss: 0.1039\n",
      "Epoch 99/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 543us/step - accuracy: 0.9642 - loss: 0.1027\n",
      "Epoch 100/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 571us/step - accuracy: 0.9636 - loss: 0.1030\n"
     ]
    }
   ],
   "source": [
    "# model optmization adding more nuerons to the hidden layers\n",
    "nn2 = nn = tf.keras.models.Sequential()\n",
    "\n",
    "nn2.add(tf.keras.layers.Dense(units=10,input_dim = input_features, activation = \"relu\" ))\n",
    "\n",
    "nn2.add(tf.keras.layers.Dense(units=8,activation = \"relu\" ))\n",
    "\n",
    "nn2.add(tf.keras.layers.Dense(units = 1,activation =\"sigmoid\"))\n",
    "\n",
    "nn2.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "fit_model = nn2.fit(X_train, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a1faed86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "752/752 - 0s - 537us/step - accuracy: 0.9621 - loss: 0.1060\n",
      "Loss: 0.10604042559862137, Accuracy: 0.9620584845542908\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = nn2.evaluate(X_test,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9a968ba5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mille\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 600us/step - accuracy: 0.9144 - loss: 0.3519\n",
      "Epoch 2/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 602us/step - accuracy: 0.9303 - loss: 0.2107\n",
      "Epoch 3/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 596us/step - accuracy: 0.9411 - loss: 0.1687\n",
      "Epoch 4/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 578us/step - accuracy: 0.9492 - loss: 0.1455\n",
      "Epoch 5/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 572us/step - accuracy: 0.9533 - loss: 0.1300\n",
      "Epoch 6/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 565us/step - accuracy: 0.9569 - loss: 0.1250\n",
      "Epoch 7/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 555us/step - accuracy: 0.9548 - loss: 0.1241\n",
      "Epoch 8/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 552us/step - accuracy: 0.9578 - loss: 0.1185\n",
      "Epoch 9/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 548us/step - accuracy: 0.9574 - loss: 0.1199\n",
      "Epoch 10/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 552us/step - accuracy: 0.9580 - loss: 0.1209\n",
      "Epoch 11/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 549us/step - accuracy: 0.9573 - loss: 0.1205\n",
      "Epoch 12/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 547us/step - accuracy: 0.9570 - loss: 0.1199\n",
      "Epoch 13/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 550us/step - accuracy: 0.9561 - loss: 0.1210\n",
      "Epoch 14/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 561us/step - accuracy: 0.9577 - loss: 0.1194\n",
      "Epoch 15/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 570us/step - accuracy: 0.9584 - loss: 0.1168\n",
      "Epoch 16/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 560us/step - accuracy: 0.9574 - loss: 0.1195\n",
      "Epoch 17/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 566us/step - accuracy: 0.9595 - loss: 0.1157\n",
      "Epoch 18/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 566us/step - accuracy: 0.9596 - loss: 0.1144\n",
      "Epoch 19/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 559us/step - accuracy: 0.9575 - loss: 0.1190\n",
      "Epoch 20/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 561us/step - accuracy: 0.9605 - loss: 0.1135\n",
      "Epoch 21/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 565us/step - accuracy: 0.9602 - loss: 0.1130\n",
      "Epoch 22/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 569us/step - accuracy: 0.9600 - loss: 0.1145\n",
      "Epoch 23/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 565us/step - accuracy: 0.9594 - loss: 0.1168\n",
      "Epoch 24/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 566us/step - accuracy: 0.9596 - loss: 0.1139\n",
      "Epoch 25/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 562us/step - accuracy: 0.9609 - loss: 0.1108\n",
      "Epoch 26/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 561us/step - accuracy: 0.9615 - loss: 0.1128\n",
      "Epoch 27/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 587us/step - accuracy: 0.9597 - loss: 0.1138\n",
      "Epoch 28/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 570us/step - accuracy: 0.9599 - loss: 0.1127\n",
      "Epoch 29/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 570us/step - accuracy: 0.9588 - loss: 0.1154\n",
      "Epoch 30/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 593us/step - accuracy: 0.9602 - loss: 0.1106\n",
      "Epoch 31/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 595us/step - accuracy: 0.9599 - loss: 0.1139\n",
      "Epoch 32/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 588us/step - accuracy: 0.9615 - loss: 0.1097\n",
      "Epoch 33/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 563us/step - accuracy: 0.9603 - loss: 0.1119\n",
      "Epoch 34/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 567us/step - accuracy: 0.9611 - loss: 0.1093\n",
      "Epoch 35/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 593us/step - accuracy: 0.9610 - loss: 0.1123\n",
      "Epoch 36/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 598us/step - accuracy: 0.9607 - loss: 0.1127\n",
      "Epoch 37/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 560us/step - accuracy: 0.9610 - loss: 0.1109\n",
      "Epoch 38/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 572us/step - accuracy: 0.9626 - loss: 0.1076\n",
      "Epoch 39/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 579us/step - accuracy: 0.9601 - loss: 0.1131\n",
      "Epoch 40/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 592us/step - accuracy: 0.9601 - loss: 0.1131\n",
      "Epoch 41/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 590us/step - accuracy: 0.9610 - loss: 0.1105\n",
      "Epoch 42/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 599us/step - accuracy: 0.9613 - loss: 0.1095\n",
      "Epoch 43/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 570us/step - accuracy: 0.9610 - loss: 0.1096\n",
      "Epoch 44/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 569us/step - accuracy: 0.9615 - loss: 0.1075\n",
      "Epoch 45/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 573us/step - accuracy: 0.9616 - loss: 0.1108\n",
      "Epoch 46/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 565us/step - accuracy: 0.9619 - loss: 0.1073\n",
      "Epoch 47/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 570us/step - accuracy: 0.9624 - loss: 0.1055\n",
      "Epoch 48/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 577us/step - accuracy: 0.9613 - loss: 0.1105\n",
      "Epoch 49/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 571us/step - accuracy: 0.9601 - loss: 0.1108\n",
      "Epoch 50/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 577us/step - accuracy: 0.9630 - loss: 0.1068\n",
      "Epoch 51/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 570us/step - accuracy: 0.9620 - loss: 0.1081\n",
      "Epoch 52/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 575us/step - accuracy: 0.9612 - loss: 0.1096\n",
      "Epoch 53/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 568us/step - accuracy: 0.9622 - loss: 0.1089\n",
      "Epoch 54/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 575us/step - accuracy: 0.9622 - loss: 0.1089\n",
      "Epoch 55/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 572us/step - accuracy: 0.9619 - loss: 0.1082\n",
      "Epoch 56/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 556us/step - accuracy: 0.9619 - loss: 0.1079\n",
      "Epoch 57/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 562us/step - accuracy: 0.9607 - loss: 0.1099\n",
      "Epoch 58/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 556us/step - accuracy: 0.9619 - loss: 0.1089\n",
      "Epoch 59/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 553us/step - accuracy: 0.9621 - loss: 0.1052\n",
      "Epoch 60/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 545us/step - accuracy: 0.9609 - loss: 0.1084\n",
      "Epoch 61/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 549us/step - accuracy: 0.9611 - loss: 0.1100\n",
      "Epoch 62/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 556us/step - accuracy: 0.9624 - loss: 0.1067\n",
      "Epoch 63/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 565us/step - accuracy: 0.9622 - loss: 0.1062\n",
      "Epoch 64/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 557us/step - accuracy: 0.9631 - loss: 0.1055\n",
      "Epoch 65/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 564us/step - accuracy: 0.9617 - loss: 0.1085\n",
      "Epoch 66/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 565us/step - accuracy: 0.9625 - loss: 0.1070\n",
      "Epoch 67/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 559us/step - accuracy: 0.9621 - loss: 0.1064\n",
      "Epoch 68/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 562us/step - accuracy: 0.9623 - loss: 0.1064\n",
      "Epoch 69/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 595us/step - accuracy: 0.9607 - loss: 0.1088\n",
      "Epoch 70/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 576us/step - accuracy: 0.9622 - loss: 0.1075\n",
      "Epoch 71/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 580us/step - accuracy: 0.9634 - loss: 0.1061\n",
      "Epoch 72/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 561us/step - accuracy: 0.9626 - loss: 0.1057\n",
      "Epoch 73/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 558us/step - accuracy: 0.9634 - loss: 0.1038\n",
      "Epoch 74/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 553us/step - accuracy: 0.9620 - loss: 0.1063\n",
      "Epoch 75/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 556us/step - accuracy: 0.9621 - loss: 0.1079\n",
      "Epoch 76/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 560us/step - accuracy: 0.9612 - loss: 0.1066\n",
      "Epoch 77/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 574us/step - accuracy: 0.9628 - loss: 0.1061\n",
      "Epoch 78/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 559us/step - accuracy: 0.9622 - loss: 0.1060\n",
      "Epoch 79/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 563us/step - accuracy: 0.9635 - loss: 0.1050\n",
      "Epoch 80/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 573us/step - accuracy: 0.9625 - loss: 0.1059\n",
      "Epoch 81/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 574us/step - accuracy: 0.9619 - loss: 0.1065\n",
      "Epoch 82/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 578us/step - accuracy: 0.9637 - loss: 0.1036\n",
      "Epoch 83/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 581us/step - accuracy: 0.9632 - loss: 0.1044\n",
      "Epoch 84/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 567us/step - accuracy: 0.9632 - loss: 0.1031\n",
      "Epoch 85/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 564us/step - accuracy: 0.9640 - loss: 0.1042\n",
      "Epoch 86/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 577us/step - accuracy: 0.9632 - loss: 0.1052\n",
      "Epoch 87/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 566us/step - accuracy: 0.9637 - loss: 0.1038\n",
      "Epoch 88/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 573us/step - accuracy: 0.9625 - loss: 0.1047\n",
      "Epoch 89/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 570us/step - accuracy: 0.9621 - loss: 0.1080\n",
      "Epoch 90/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 569us/step - accuracy: 0.9617 - loss: 0.1075\n",
      "Epoch 91/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 572us/step - accuracy: 0.9622 - loss: 0.1056\n",
      "Epoch 92/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 558us/step - accuracy: 0.9622 - loss: 0.1076\n",
      "Epoch 93/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 557us/step - accuracy: 0.9628 - loss: 0.1051\n",
      "Epoch 94/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 561us/step - accuracy: 0.9631 - loss: 0.1039\n",
      "Epoch 95/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 565us/step - accuracy: 0.9636 - loss: 0.1038\n",
      "Epoch 96/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 580us/step - accuracy: 0.9626 - loss: 0.1041\n",
      "Epoch 97/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 566us/step - accuracy: 0.9628 - loss: 0.1045\n",
      "Epoch 98/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 576us/step - accuracy: 0.9631 - loss: 0.1056\n",
      "Epoch 99/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 575us/step - accuracy: 0.9630 - loss: 0.1025\n",
      "Epoch 100/100\n",
      "\u001b[1m2254/2254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 569us/step - accuracy: 0.9652 - loss: 0.1001\n"
     ]
    }
   ],
   "source": [
    "# model optmization adding another hidden layer\n",
    "nn3 = nn = tf.keras.models.Sequential()\n",
    "\n",
    "nn3.add(tf.keras.layers.Dense(units=10,input_dim = input_features, activation = \"relu\" ))\n",
    "\n",
    "nn3.add(tf.keras.layers.Dense(units=8,activation = \"relu\" ))\n",
    "\n",
    "nn3.add(tf.keras.layers.Dense(units=6, activation = \"relu\"))\n",
    "\n",
    "nn3.add(tf.keras.layers.Dense(units = 1,activation =\"sigmoid\"))\n",
    "\n",
    "nn3.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "fit_model = nn3.fit(X_train, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2f2688b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "752/752 - 0s - 527us/step - accuracy: 0.9605 - loss: 0.1169\n",
      "Loss: 0.11691159754991531, Accuracy: 0.9604775905609131\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = nn3.evaluate(X_test,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a728124",
   "metadata": {},
   "source": [
    "# Use keras tuner to optimize the nn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "880d4a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(hp):\n",
    "    nn_hp_model = tf.keras.models.Sequential()\n",
    "\n",
    "    # Allow kerastuner to decide which activation function to use in hidden layers\n",
    "    activation = hp.Choice('activation',['relu','tanh','sigmoid'])\n",
    "    \n",
    "    # Allow kerastuner to decide number of neurons in first layer\n",
    "    nn_hp_model.add(tf.keras.layers.Dense(units=hp.Int('first_units',\n",
    "        min_value=1,\n",
    "        max_value=100,\n",
    "        step=5), activation=activation, input_dim=input_features))\n",
    "\n",
    "    # Allow kerastuner to decide number of hidden layers and neurons in hidden layers\n",
    "    for i in range(hp.Int('num_layers', 1, 6)):\n",
    "        nn_hp_model.add(tf.keras.layers.Dense(units=hp.Int('units_' + str(i),\n",
    "            min_value=1,\n",
    "            max_value=100,\n",
    "            step=5),\n",
    "            activation=activation))\n",
    "    \n",
    "    nn_hp_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "    # Compile the model\n",
    "    nn_hp_model.compile(loss=\"binary_crossentropy\", optimizer='adam', metrics=[\"accuracy\"])\n",
    "    \n",
    "    return nn_hp_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8cdd3704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from .\\untitled_project\\tuner0.json\n"
     ]
    }
   ],
   "source": [
    "tuner = kt.Hyperband(\n",
    "    create_model,\n",
    "    objective=\"val_accuracy\",\n",
    "    max_epochs=20,\n",
    "    hyperband_iterations=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "487d06e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 56 Complete [00h 00m 36s]\n",
      "val_accuracy: 0.9691725373268127\n",
      "\n",
      "Best val_accuracy So Far: 0.9698381423950195\n",
      "Total elapsed time: 00h 23m 15s\n"
     ]
    }
   ],
   "source": [
    "tuner.search(X_train_scaled,y_train,epochs=20,validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "70fbd65c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation': 'tanh',\n",
       " 'first_units': 86,\n",
       " 'num_layers': 6,\n",
       " 'units_0': 16,\n",
       " 'units_1': 91,\n",
       " 'units_2': 51,\n",
       " 'units_3': 36,\n",
       " 'units_4': 86,\n",
       " 'units_5': 6,\n",
       " 'tuner/epochs': 20,\n",
       " 'tuner/initial_epoch': 0,\n",
       " 'tuner/bracket': 0,\n",
       " 'tuner/round': 0}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_hyper = tuner.get_best_hyperparameters(1)[0]\n",
    "best_hyper.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "8959c853",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mille\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "C:\\Users\\mille\\anaconda3\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:396: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 34 variables. \n",
      "  trackable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "752/752 - 1s - 726us/step - accuracy: 0.9698 - loss: 0.0888\n",
      "Loss: 0.08878502249717712, Accuracy: 0.9698381423950195\n"
     ]
    }
   ],
   "source": [
    "best_model = tuner.get_best_models(1)[0]\n",
    "model_loss, model_accuracy = best_model.evaluate(X_test,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295c71c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
